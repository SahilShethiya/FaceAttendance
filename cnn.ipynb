{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "import seaborn as sns # additional plotting functionality\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['Alex','Ananya','Kavisha','Mithun','Sahil','Sonu','Tom','Dhruv','Ethan','Premal']\n",
    "#reading file\n",
    "csvFile = pd.read_csv('images_path.csv')\n",
    "print(len(csvFile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(csvFile['Images'],csvFile['Labels'],test_size=0.3,stratify=csvFile['Labels'])\n",
    "\n",
    "print(len(train_x))\n",
    "print(len(test_x))\n",
    "\n",
    "train_data = {'Images':train_x,'Labels':train_y}\n",
    "test_data = {'Images':train_x,'Labels':train_y}\n",
    "\n",
    "# you can also create val set like this but right now i am creating only test and val set\n",
    "train = pd.DataFrame(train_data)\n",
    "test = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (299, 299)\n",
    "core_idg = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=5, \n",
    "                              shear_range = 0.1,\n",
    "                              zoom_range=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = core_idg.flow_from_dataframe(dataframe=csvFile,\n",
    "directory=None,\n",
    "x_col = 'Images',\n",
    "y_col = 'Labels',\n",
    "class_mode = 'categorical',\n",
    "classes = classes,\n",
    "target_size = image_size,\n",
    "color_mode = 'rgb',\n",
    "batch_size = 32)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_gen = test_datagen.flow_from_dataframe(dataframe=csvFile,\n",
    "directory=None,\n",
    "x_col = 'Images',\n",
    "y_col = 'Labels',\n",
    "class_mode = 'categorical',\n",
    "classes = classes,\n",
    "target_size = image_size,\n",
    "color_mode = 'rgb',\n",
    "batch_size = 32)\n",
    "\n",
    "test_X, test_Y = next(core_idg.flow_from_dataframe(dataframe=csvFile,\n",
    "directory=None,\n",
    "x_col = 'Images',\n",
    "y_col = 'Labels',\n",
    "lass_mode = 'categorical',\n",
    "classes = classes,\n",
    "target_size = image_size,\n",
    "color_mode = 'rgb',\n",
    "batch_size = 1024,\n",
    "#validation_split=0.3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create CNN model\n",
    "# Will use a combination of convolutional, max pooling, and dropout layers for this purpose\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 8, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = test_X.shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.2))\n",
    "          \n",
    "model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 3))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# add in fully connected dense layers to model, then output classifiction probabilities using a softmax activation function\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3000, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2000, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(classes), activation = 'softmax'))\n",
    "\n",
    "# compile model, run summary\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpointer = ModelCheckpoint(filepath='weights.best.hdf5', verbose=1, save_best_only = True)\n",
    "#callbacks_list = [checkpointer]\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='cnn_accuracy',\n",
    "    save_weights_only=True,\n",
    "    #monitor='accuracy',\n",
    "    mode='max',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator = train_gen, steps_per_epoch = 2, epochs = 250, callbacks = callbacks_list,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model.predict(test_X, batch_size = 32, verbose = 1)\n",
    "#model.evaluate(test_X,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(test_X, test_Y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(test_X, batch_size=20, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "print(y_pred_bool)\n",
    "test_Y = np.argmax(test_Y, axis=1)\n",
    "print(classification_report(test_Y, y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
